{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"14UsF7NxcK8bLC5I34TKkxc_mXOanvjx9","authorship_tag":"ABX9TyOiD3ZOs6+SnK5oAs6z6+XR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["---\n","# 설치\n","---"],"metadata":{"id":"0iSoH5jNwQEj"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXNErloIvyTT","executionInfo":{"status":"ok","timestamp":1662091516339,"user_tz":-540,"elapsed":3863,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"8fe1ce10-f489-4eed-d3f4-2e6d4db60ab0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","source":["---\n","# 모델 불러오기\n","----"],"metadata":{"id":"IMh03Q2BwTB6"}},{"cell_type":"code","source":["# kobert Model 불러오기\n","from transformers import AutoModelForMaskedLM\n","\n","model_checkpoint = \"klue/bert-base\"\n","model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uW7E4i1ywHvS","executionInfo":{"status":"ok","timestamp":1662099196106,"user_tz":-540,"elapsed":2795,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"cb29d5ac-568c-4c05-87c4-40f2e2c3a954"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n","Model config BertConfig {\n","  \"_name_or_path\": \"klue/bert-base\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n","loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n","Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of BertForMaskedLM were initialized from the model checkpoint at klue/bert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"]}]},{"cell_type":"code","source":["# kobert Tokenizer 불러오기 \n","from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSq9Mi_Kwhoj","executionInfo":{"status":"ok","timestamp":1662099198357,"user_tz":-540,"elapsed":2255,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"7986fb3f-d6eb-467b-9969-1d95951003c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n","Model config BertConfig {\n","  \"_name_or_path\": \"klue/bert-base\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n","loading file https://huggingface.co/klue/bert-base/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/1a36e69d48a008e522b75e43693002ffc8b6e6df72de7c53412c23466ec165eb.085110015ec67fc02ad067f712a7c83aafefaf31586a3361dd800bcac635b456\n","loading file https://huggingface.co/klue/bert-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/310a974e892b181d75eed58b545cc0592d066ae4ef35cc760ea92e9b0bf65b3b.74f7933572f937b11a02b2cfb4e88a024059be36c84f53241b85b1fec49e21f7\n","loading file https://huggingface.co/klue/bert-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/klue/bert-base/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/aeaaa3afd086a040be912f92ffe7b5f85008b744624f4517c4216bcc32b51cf0.054ece8d16bd524c8a00f0e8a976c00d5de22a755ffb79e353ee2954d9289e26\n","loading file https://huggingface.co/klue/bert-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f8f71eb411bb03f57b455cfb1b4e04ae124201312e67a3ad66e0a92d0c228325.78871951edcb66032caa0a9628d77b3557c23616c653dacdb7a1a8f33011a843\n","loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n","Model config BertConfig {\n","  \"_name_or_path\": \"klue/bert-base\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n"]}]},{"cell_type":"code","source":["import torch\n","text = \"그는 어제 [MASK]를 먹었다.\"\n","\n","inputs = tokenizer(text, return_tensors = 'pt')\n","\n","token_logits = model(**inputs).logits\n","\n","mask_token_index = torch.where(inputs['input_ids'] == tokenizer.mask_token_id)[1]\n","mask_token_logits = token_logits[0, mask_token_index, :]\n","\n","# torch.topk 주어진 차원을 따라 주어진 텐서 의 k가장 큰 요소를 반환\n","top_5_tokens = torch.topk(mask_token_logits,5, dim=1).indices[0].tolist()\n","\n","for token in top_5_tokens:\n","  print(f\">>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AjpxpEy78naL","executionInfo":{"status":"ok","timestamp":1662099198656,"user_tz":-540,"elapsed":301,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"ef8828f6-072c-4751-d83d-c8be6a1f0e67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[">>> 그는 어제 브런치를 먹었다.\n",">>> 그는 어제 저녁를 먹었다.\n",">>> 그는 어제 샌드위치를 먹었다.\n",">>> 그는 어제 샐러드를 먹었다.\n",">>> 그는 어제 햄버거를 먹었다.\n"]}]},{"cell_type":"code","source":["tokenizer.tokenize(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8RTL4vBiHix","executionInfo":{"status":"ok","timestamp":1662099198656,"user_tz":-540,"elapsed":5,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"69f001fb-b744-4ad5-8c35-c643554e9f6b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['그', '##는', '어제', '[MASK]', '를', '먹', '##었', '##다', '.']"]},"metadata":{},"execution_count":145}]},{"cell_type":"code","source":["inputs.items()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5oBVpNaTbO9Q","executionInfo":{"status":"ok","timestamp":1662099198656,"user_tz":-540,"elapsed":3,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"bfa7435f-2d49-4603-9400-5529e57c7578"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_items([('input_ids', tensor([[   2,  636, 2259, 5538,    4, 1022, 1059, 2359, 2062,   18,    3]])), ('token_type_ids', tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])), ('attention_mask', tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))])"]},"metadata":{},"execution_count":146}]},{"cell_type":"markdown","source":["---\n","# 데이터 불러오기 \n","---"],"metadata":{"id":"EyN7BOQRP8bm"}},{"cell_type":"code","source":["import pandas as pd \n","\n","data = pd.read_csv('/content/drive/MyDrive/aiffel/AIFFELTON/for_model_labeling_folder/check_jang_0830.csv')\n","del data['Unnamed: 0']\n","data = data.sample(frac = 1)\n","data = data.reset_index(drop = True)\n","data2 = data[6000 : ]\n","data = data[:6000]\n","data"],"metadata":{"id":"cxaaxWNMCYM-","executionInfo":{"status":"ok","timestamp":1662099204085,"user_tz":-540,"elapsed":334,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"7a47fc5d-7e4c-4a6b-b3bd-84afd55c324c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                 review  taste  quantity  \\\n","0     떡볶이는 너무 달고 어묵 국물은 너무 짜고 순대간은 원래 그렇게 부서지는건가요 ㅠ ...      1         0   \n","1     짬짜면이 정말 짬뽕 짜장면이네요ㅋㅋ 아니 맞는 말이긴한데 음식사진이랑 차이가 너무 ...      1         0   \n","2                                             먹을만은했어용용요      1         0   \n","3                                              정말 맛있었어요      1         0   \n","4            간장은 맛있어요 새콤달콤한 맛으로 양념을 먹는데 매워서 맛을 못느끼겠네요 ㅠ      1         0   \n","...                                                 ...    ...       ...   \n","5995  두마리치킨이다보니 닭이 작고 작고 오래튀긴듯한 느낌에 다리살도 질기네요 페리카나 양...      1         0   \n","5996                                 내가 먹은 피자중에 최 악 이였다      1         0   \n","5997                              내가알던 동대문 엽기 떡볶이가아니였어요      0         0   \n","5998                                   삼겹살 먹고 싶으면 추천합니다      1         0   \n","5999          죠리퐁쉐이크한번먹고 중독됬습니다 근데 일하느라대전에없어서 옷먹는게아쉽네요ㅠ      0         0   \n","\n","      delivery  \n","0            0  \n","1            0  \n","2            0  \n","3            0  \n","4            0  \n","...        ...  \n","5995         0  \n","5996         0  \n","5997         0  \n","5998         0  \n","5999         0  \n","\n","[6000 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-8f1c51a8-b592-4c10-b4a1-fd52f3169a62\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>taste</th>\n","      <th>quantity</th>\n","      <th>delivery</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>떡볶이는 너무 달고 어묵 국물은 너무 짜고 순대간은 원래 그렇게 부서지는건가요 ㅠ ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>짬짜면이 정말 짬뽕 짜장면이네요ㅋㅋ 아니 맞는 말이긴한데 음식사진이랑 차이가 너무 ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>먹을만은했어용용요</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>정말 맛있었어요</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>간장은 맛있어요 새콤달콤한 맛으로 양념을 먹는데 매워서 맛을 못느끼겠네요 ㅠ</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5995</th>\n","      <td>두마리치킨이다보니 닭이 작고 작고 오래튀긴듯한 느낌에 다리살도 질기네요 페리카나 양...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5996</th>\n","      <td>내가 먹은 피자중에 최 악 이였다</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5997</th>\n","      <td>내가알던 동대문 엽기 떡볶이가아니였어요</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5998</th>\n","      <td>삼겹살 먹고 싶으면 추천합니다</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5999</th>\n","      <td>죠리퐁쉐이크한번먹고 중독됬습니다 근데 일하느라대전에없어서 옷먹는게아쉽네요ㅠ</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6000 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f1c51a8-b592-4c10-b4a1-fd52f3169a62')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8f1c51a8-b592-4c10-b4a1-fd52f3169a62 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8f1c51a8-b592-4c10-b4a1-fd52f3169a62');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":147}]},{"cell_type":"code","source":["data2.to_csv('/content/drive/MyDrive/aiffel/AIFFELTON/for_model_labeling_folder/MLM 후 나머지.csv')\n","data.to_csv('/content/drive/MyDrive/aiffel/AIFFELTON/for_model_labeling_folder/MLM_dataset.txt')"],"metadata":{"id":"Ivguif1CUuBg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np \n","\n","total_data_text = list(data['review'])\n","# 텍스트데이터 문장길이의 리스트를 생성한 후\n","num_tokens = [len(tokens) for tokens in total_data_text]\n","num_tokens = np.array(num_tokens)\n","# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n","print('문장길이 평균 : ', np.mean(num_tokens))\n","print('문장길이 최대 : ', np.max(num_tokens))\n","print('문장길이 표준편차 : ', np.std(num_tokens))\n","\n","# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n","max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n","maxlen = int(max_tokens)\n","print('pad_sequences maxlen : ', maxlen)\n","print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4fwui4CVQaN","executionInfo":{"status":"ok","timestamp":1662099209107,"user_tz":-540,"elapsed":330,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"f5c5f415-b020-4b53-db64-247cc9ac754e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["문장길이 평균 :  32.912333333333336\n","문장길이 최대 :  99\n","문장길이 표준편차 :  22.871524826493072\n","pad_sequences maxlen :  78\n","전체 문장의 0.935%가 maxlen 설정값 이내에 포함됩니다. \n"]}]},{"cell_type":"code","source":["# class CustomDataset(Dataset):\n","  \n","#   def __init__(self, data, idx):\n","#     self.data = data\n","#     self.idx = idx\n","  \n","#   def __len__(self):\n","#     return len(self.data)\n","\n","#   def __getitem__(self, idx):\n","#     text = self.data['review'][idx]\n","    \n","#     return {'review' : text}"],"metadata":{"id":"nPma2404WwRD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_list = []\n","for i in range(len(data)):\n","  data_list.append(data['review'][i])"],"metadata":{"id":"fDeM0G34WVSX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def tokenize_function(example):\n","#   result = tokenizer(example['review'])\n","#   if tokenizer.is_fast: # batch_embedding의 결과에서 생성된 것인지 여부 \n","#     result['word_ids'] = [result.word_ids(i) for i in range(len(result['input_ids']))]\n","#   return result"],"metadata":{"id":"cyOQhD-kV2kZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokenized_datasets = data_list.map(tokenize_function, batched = True)  \n","# tokenized_datasets"],"metadata":{"id":"idTxF9sFV5oq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","from transformers.tokenization_utils import PreTrainedTokenizer\n","\n","class LineByLineTextDataset(Dataset):\n","\n","    def __init__(self, tokenizer: PreTrainedTokenizer, data, block_size: int):\n","\n","        batch_encoding = tokenizer(data, add_special_tokens=True, truncation=True, max_length=block_size)\n","        self.examples = batch_encoding[\"input_ids\"]\n","        # self.examples = batch_encoding[\"attention_mask\"]\n","        self.examples = [{\"input_ids\": torch.tensor(e, dtype=torch.long)} for e in self.examples]\n","        # self.examples = [{\"attention_mask\": torch.tensor(e, dtype=torch.long)} for e in self.examples]\n","        # self.examples = [{'word_ids': batch_encoding.word_ids(i) for i in range(len(self.examples['input_ids']))]\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, i):\n","        return self.examples[i]"],"metadata":{"id":"ACKxNznYWc3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# aa = tokenizer(text, add_special_tokens=True)\n","# bb = aa[\"input_ids\"]\n","# bb = [{\"input_ids\": torch.tensor(e, dtype=torch.long)} for e in bb]\n","# bb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJR_dHHEv1qk","executionInfo":{"status":"ok","timestamp":1662097958401,"user_tz":-540,"elapsed":311,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"284588b0-7afe-480b-d609-139d461e6b4b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'input_ids': tensor(2)},\n"," {'input_ids': tensor(636)},\n"," {'input_ids': tensor(2259)},\n"," {'input_ids': tensor(5538)},\n"," {'input_ids': tensor(4)},\n"," {'input_ids': tensor(1022)},\n"," {'input_ids': tensor(1059)},\n"," {'input_ids': tensor(2359)},\n"," {'input_ids': tensor(2062)},\n"," {'input_ids': tensor(18)},\n"," {'input_ids': tensor(3)}]"]},"metadata":{},"execution_count":116}]},{"cell_type":"code","source":["dataset = LineByLineTextDataset(tokenizer = tokenizer,\n","                                data = data_list,\n","                                block_size = 512)"],"metadata":{"id":"vu3S7uy0lZD6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(tokenizer= tokenizer, mlm_probability = 0.15)"],"metadata":{"id":"ELu1KSeAxzv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import TrainingArguments\n","\n","batch_size = 64\n","\n","###################### 각 에포크에서 훈련 손실을 추적 ######################\n","logging_steps = len(dataset) // batch_size\n","model_name = model_checkpoint.split(\"/\")[-1]\n","\n","training_args = TrainingArguments(\n","    output_dir=f\"{model_name}-kobert-review\",        # 모델 예측 및 체크포인트가 작성될 출력 디렉토리\n","\n","    overwrite_output_dir=True,                        # True인 경우 출력 디렉토리의 내용을 덮어쓴다. \n","                                                      # 훈련을 덮어씌우며 반복하려먼 True로 설정 필요\n","                                  \n","    evaluation_strategy=\"epoch\",                      # 훈련 중에 채택할 평가 전략\n","                                                      # \"no\": 교육 중에는 평가를 하지 않는다.\n","                                                      # \"steps\": 평가는 매 eval_steps\n","                                                      # \"epoch\": 평가는 각 Epoch가 끝날 때 수행\n","                                  \n","    learning_rate=2e-5,                               # AdamW의 학습률 \n","    weight_decay=0.01,                                # 모든 bias 및 LayerNorm 가중치를 제외한 모든 레이어에 적용할 가중치 감쇠\n","    per_device_train_batch_size=batch_size,           # 배치 크기\n","    per_device_eval_batch_size=batch_size,            # 배치 크기\n","    push_to_hub=False,\n","    fp16=True,                                        # 32비트 훈련 대신 fp16 16비트(혼합) 정밀도 훈련을 사용할지 여부\n","                                                      # weights를 fp32에서 fp16으로 변환한 후 연산을 수행하고 update 과정에서 다시 fp32로 변환해 weight를 업데이트해주는 방법론\n","                                                      # 필요한 gradients만 잘 살려서 학습 속도를 높이는 방법\n","                                  \n","    logging_steps=logging_steps,                      # 두 로그간에 업데이트 단계 수\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8jEFAo5SycFc","executionInfo":{"status":"ok","timestamp":1662099225351,"user_tz":-540,"elapsed":320,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"56738798-cb1a-4179-815a-52b96b7310f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","train_dataset ,test_dataset = train_test_split(dataset, test_size = 0.1, shuffle = True)"],"metadata":{"id":"La6cOcQ90DQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    data_collator=data_collator,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dsnVbK2Ry2dq","executionInfo":{"status":"ok","timestamp":1662099241811,"user_tz":-540,"elapsed":369,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"7aae42d8-300d-4118-a175-eea64e29d181"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cuda_amp half precision backend\n"]}]},{"cell_type":"code","source":["import math\n","\n","eval_results = trainer.evaluate()\n","print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"FV5KVmxJ1Faa","executionInfo":{"status":"ok","timestamp":1662099244842,"user_tz":-540,"elapsed":1460,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"a645dfd3-ff6c-422d-d2db-72b035d6aae2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 600\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10/10 00:01]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":[">>> Perplexity: 162.59\n"]}]},{"cell_type":"code","source":["import math\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":643},"id":"yDm7p1TpzKXY","executionInfo":{"status":"ok","timestamp":1662099360973,"user_tz":-540,"elapsed":113863,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"65cd69ea-dd51-4872-abdd-b08a6a9a11b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5400\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 255\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='255' max='255' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [255/255 01:53, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.327660</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.834200</td>\n","      <td>2.277153</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.473700</td>\n","      <td>2.205303</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 600\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10/10 00:41]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 600\n","  Batch size = 64\n","***** Running Evaluation *****\n","  Num examples = 600\n","  Batch size = 64\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=255, training_loss=2.5905276429419426, metrics={'train_runtime': 113.6859, 'train_samples_per_second': 142.498, 'train_steps_per_second': 2.243, 'total_flos': 476544646643712.0, 'train_loss': 2.5905276429419426, 'epoch': 3.0})"]},"metadata":{},"execution_count":158}]},{"cell_type":"code","source":["eval_results = trainer.evaluate()\n","print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"UF-pOL3czKyY","executionInfo":{"status":"ok","timestamp":1662099362165,"user_tz":-540,"elapsed":1209,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"4445ba1c-504a-481e-f276-da241467c0a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 600\n","  Batch size = 64\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10/10 00:01]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":[">>> Perplexity: 9.29\n"]}]},{"cell_type":"markdown","source":["---\n","# pretrained model save\n","---"],"metadata":{"id":"DeUmICwB4NcI"}},{"cell_type":"code","source":["model.save_pretrained('/content/drive/MyDrive/aiffel/AIFFELTON/TAPT_Model_Save')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xE9xZ5RM1dZX","executionInfo":{"status":"ok","timestamp":1662100060722,"user_tz":-540,"elapsed":1912,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"15f07ca1-18e5-4421-8c56-e08269194829"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Configuration saved in /content/drive/MyDrive/aiffel/AIFFELTON/TAPT_Model_Save/config.json\n","Model weights saved in /content/drive/MyDrive/aiffel/AIFFELTON/TAPT_Model_Save/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["tokenizer.save_pretrained('/content/drive/MyDrive/aiffel/AIFFELTON/TAPT_Model_Save')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2oFx2Gz4jDs","executionInfo":{"status":"ok","timestamp":1662100086493,"user_tz":-540,"elapsed":606,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"1b5e1c3f-ca5d-4965-e958-ab2f50d3129b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["tokenizer config file saved in /content/drive/MyDrive/aiffel/AIFFELTON/TAPT_Model_Save/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/aiffel/AIFFELTON/TAPT_Model_Save/special_tokens_map.json\n"]},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/aiffel/AIFFELTON/TAPT_Model_Save/tokenizer_config.json',\n"," '/content/drive/MyDrive/aiffel/AIFFELTON/TAPT_Model_Save/special_tokens_map.json',\n"," '/content/drive/MyDrive/aiffel/AIFFELTON/TAPT_Model_Save/vocab.txt',\n"," '/content/drive/MyDrive/aiffel/AIFFELTON/TAPT_Model_Save/added_tokens.json',\n"," '/content/drive/MyDrive/aiffel/AIFFELTON/TAPT_Model_Save/tokenizer.json')"]},"metadata":{},"execution_count":161}]},{"cell_type":"code","source":[],"metadata":{"id":"wRhCEIJI4pp4"},"execution_count":null,"outputs":[]}]}